{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import chat\n",
    "import numpy as np\n",
    "\n",
    "# More secure way\n",
    "incubator_endpoint = \"https://eyqincubator.america.fabric.ey.com/eyq/canadaeast/api/\"\n",
    "incubator_key = \"toNx9GPyvXRB9C6sDC8G47XAO2IKGeZV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completion(prompt):\n",
    "    \n",
    "    api_version = \"2023-05-15\"\n",
    "    \n",
    "    model = \"gpt-4-turbo\"  # Replace with desired modelS\n",
    "    \n",
    "    headers = {\n",
    "        \"x-api-key\": incubator_key\n",
    "    }\n",
    "    \n",
    "    query_params = {\n",
    "        \"api-version\": api_version\n",
    "    }\n",
    "    \n",
    "    \n",
    "    body = {\n",
    "        \"messages\":[\n",
    "            {\"role\": \"system\", \"content\": \"You're an expert software engineer specialized in Cobol and PySpark programming languages. your responsibility is translate Cobol codes into PySpark accurately and including all Proccess.\"},\n",
    "            {\"role\":\"user\",\"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    full_path = incubator_endpoint + \"/openai/deployments/\" + model + \"/chat/completions\"\n",
    "    \n",
    "    response = requests.post(full_path, json=body, headers=headers, params=query_params)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DWSD0612_completo_V3.txt', 'r') as file:\n",
    "    data = file.read().strip()\n",
    "    data = ' '.join(data.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "divisions = [\"ENVIRONMENT DIVISION\", \"DATA DIVISION\",\"PROCEDURE DIVISION\"]\n",
    "data_split = data.split('DIVISION')[2:]\n",
    "for i,row in enumerate(data_split):\n",
    "    final.append(f'{divisions[i]} {row}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# responses = []\n",
    "# for code in tqdm(final):\n",
    "#     time.sleep(1)\n",
    "#     response = completion(prompt=f\"\"\"\n",
    "#     Given the following Cobol code, translate it into PySpark code:\n",
    "\n",
    "#     {code}\n",
    "            \n",
    "#     Ensure that the PySpark code includes all the necessary processes.\n",
    "#     Return Only the Pyspark Code\n",
    "#     \"\"\")\n",
    "#     try:\n",
    "#         responses.append(response.json())\n",
    "#     except:\n",
    "#         responses.append(response.text)\n",
    "\n",
    "usage = []\n",
    "responses = []\n",
    "for code in tqdm(final):\n",
    "    response = chat.generate(prompt=f\"\"\"Given the following COBOL code snippet. Your role will be to decipher the COBOL code, create an equivalent PySpark code with the same functionality, including all the necessary processes.\n",
    "\n",
    "COBOL code:\n",
    "\n",
    "```\n",
    "{code}\n",
    "```\n",
    "\n",
    "Your task is to do the following steps:\n",
    "\n",
    "1. Analyze and comprehend the COBOL code snippet above.\n",
    "2. Write an equivalent PySpark code.\n",
    "3. The equivalent code should provide the exact same output as the COBOL code.\n",
    "4. Follow best practices while crafting your code, like writing clean, well-indented, efficient, and concise code.\n",
    "6. Return only the PySpark code in the response.\"\"\",temperature=0.1)\n",
    "    responses.append(response)\n",
    "    usage.append(((response.usage.prompt_tokens/1000) * 0.006)+((response.usage.completion_tokens/1000) * 0.012))\n",
    "print(np.sum(usage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# sparks = []\n",
    "# for resp in  responses:\n",
    "\n",
    "#     code = re.findall(r'```python\\n(.*?)```', resp.choices[0].message.content, re.DOTALL)[0]\n",
    "#     sparks.append(f'```python\\n {code} ```') \n",
    "# final_sparks = '\\n\\n\\n '.join(sparks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sparks = '\\n\\n'.join(resp.choices[0].message.content for resp in responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for resp in  responses:\n",
    "    with open(\"Outputs/Cobol2Spark_teste_34.md\", \"w\") as text_file:\n",
    "        text_file.write(final_sparks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_code = chat.generate(prompt=f\"\"\"Given the following PySpark code snippet. Your role will be to decipher the code, rearrange the code and return the PySpark code focusing in Clean code, well-indented, efficient, and concise code.\n",
    "                            \n",
    "\n",
    "Pyspark code:\n",
    "\n",
    "```\n",
    "{final_sparks}\n",
    "```\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "1. Analyze and comprehend the PySpark code snippet above.\n",
    "2. Clean the code, make it well-indented, efficient, and concise code.\n",
    "3. Follow best practices while crafting your code, like writing clean, well-indented, efficient, and concise code.\n",
    "6. Return only the PySpark code.\"\"\",temperature=0.7)\n",
    "\n",
    "print(((response.usage.prompt_tokens/1000) * 0.006)+((response.usage.completion_tokens/1000) * 0.012))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for resp in  responses:\n",
    "    with open(\"Outputs/Cobol2Spark_teste_33.md\", \"w\") as text_file:\n",
    "        text_file.write(final_code.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
