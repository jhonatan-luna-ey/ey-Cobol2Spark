{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import Cobol2Spark as chat\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DWSD0612_completo_V3.txt', 'r') as file:\n",
    "    data = file.read().strip()\n",
    "    data = ' '.join(data.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "divisions = [\"ENVIRONMENT DIVISION\", \"DATA DIVISION\",\"PROCEDURE DIVISION\"]\n",
    "data_split = data.split('DIVISION')[2:]\n",
    "for i,row in enumerate(data_split):\n",
    "    final.append(f'{divisions[i]} {row}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:15<00:00, 45.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.158646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "usage = []\n",
    "explains = []\n",
    "responses = []\n",
    "for code in tqdm(final):\n",
    "    explanation = chat.generate(prompt=f\"\"\"Given the following code snippet. Your role will be to decipher the code, create an in-depth explanation of code providing all functionality, including all the necessary processes.\n",
    "\n",
    "    code:\n",
    "    ```\n",
    "    {code}\n",
    "    ```\n",
    "\n",
    "    Your task is to do the following steps:\n",
    "\n",
    "    1. Analyze and comprehend the COBOL code snippet above.\n",
    "    2. Write an in-depth step by step Explanation of code.\n",
    "    3. Documentaion should provide detailed step by step with all proccess made in code.\n",
    "    4. pay attention in all data input and output steps like data reading, data writing, and data loading.\n",
    "    4. Pay extra attention in the every data processing steps like filtering, aggregation, and sorting.\n",
    "    5. Pay attention in every data manipulation steps like data cleaning, data transformation, and data wrangling.\n",
    "    \"\"\",temperature=0.4, max_tokens=1000)\n",
    "\n",
    "    code = chat.generate(prompt=f\"\"\"Given the following code snippet and the explaination of code Your role will be to decipher the code, create an  PySpark code with the same functionality, including all the necessary processes.\n",
    "\n",
    "    explanation:\n",
    "    ```\n",
    "    {explanation.choices[0].message.content}\n",
    "    ```\n",
    "    code:\n",
    "    ```\n",
    "    {code}\n",
    "    ```\n",
    "\n",
    "    Your task is to do the following steps:\n",
    "\n",
    "    1. Analyze and comprehend the COBOL code snippet above.\n",
    "    2. Write an equivalent PySpark code.\n",
    "    3. The equivalent code should provide the exact same output as the COBOL code.\n",
    "    4. Pay extra attention in the every data processing steps like filtering, aggregation, and sorting.\n",
    "    5. Follow best practices while crafting your code, like writing clean, well-indented, efficient, and concise code.\n",
    "    6. Return only the PySpark code.\n",
    "    \"\"\",temperature=0.4, max_tokens=1000)\n",
    "    responses.append(response)\n",
    "    usage.append(((response.usage.prompt_tokens/1000) * 0.006)+((response.usage.completion_tokens/1000) * 0.012))\n",
    "print(np.sum(usage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentation = '\\n\\n'.join(resp.choices[0].message.content for resp in responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given COBOL code is quite extensive and involves many steps. Let's break it down into sections and explain each part:\n",
      "\n",
      "1. **File and Data Definitions**: The code starts with the definition of several files (ARQPARM, ARQSORT, DIMESTIP, ARQFTP) and their associated data structures. Each file has a specific layout defined using the PIC clause, which describes the type and size of each field. For instance, ARQSORT contains fields like NUM-CGC-SORT, DATA-CANCEL-SORT, DATA-INIC-SORT, and others. \n",
      "\n",
      "2. **Working Storage Section**: This section defines various temporary variables and constants that will be used throughout the program. For example, WS-SDCDSUC, WS-ABEND, WS-SQLCODE, etc. These variables are used for different purposes such as error handling, storing intermediate results, and controlling program flow.\n",
      "\n",
      "3. **SQL Statements and Table Definitions**: The code includes several EXEC SQL statements that interact with a DB2 database. These statements include table definitions (e.g., ATSAUDAO.SSCESTIPULANTE, DBSISA.DESC, DBSISA.MOVI) and a cursor declaration (CURSOR-ATETP) for retrieving data from the database. \n",
      "\n",
      "4. **Linkage Section**: This section defines the parameters that are passed to and from the program. The PARAMETRO structure is defined here, which includes fields like PERIODICIDADE, AMBIENTE, DIRETORIO-PRODUCAO, and DIRETORIO-DESENVOLVIMENTO.\n",
      "\n",
      "5. **Procedure Division**: This is where the main logic of the program would be written. However, the Procedure Division is not included in the provided code snippet.\n",
      "\n",
      "In terms of data input and output:\n",
      "- Input: The program reads data from the defined files and the DB2 database using the declared cursor. \n",
      "- Output: The program would typically write data to files or the database, but this part of the code is not provided.\n",
      "\n",
      "In terms of data processing:\n",
      "- The program likely performs operations such as filtering and sorting on the data retrieved from the database using the cursor. However, the specific operations are not visible in the provided code snippet.\n",
      "\n",
      "In terms of data manipulation:\n",
      "- The program likely performs data cleaning, transformation, and wrangling using the variables defined in the Working Storage Section. However, the specific operations are not visible in the provided code snippet.\n"
     ]
    }
   ],
   "source": [
    "print(responses[1].choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "sparks = []\n",
    "for resp in  responses:\n",
    "    code = '\\n\\n'.join(re.findall(r'```python\\n(.*?)```', resp.choices[0].message.content, re.DOTALL))\n",
    "    sparks.append(code) \n",
    "final_sparks = '\\n\\n\\n '.join(sparks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cobol_final = '\\n\\n'.join(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_code = chat.generate(prompt=f\"\"\"Analise the following codes snippet and decipher the code.\n",
    "                            \n",
    "\n",
    "cobol code:\n",
    "```\n",
    "{cobol_final}\n",
    "```\n",
    "\n",
    "Pyspark code:\n",
    "```\n",
    "{final_sparks}\n",
    "```\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "1. Analyze and comprehend the PySpark and cobol code snippet above.\n",
    "2. verify if in the Spark code there is any mistake or if it is not equivalent to the COBOL code.\n",
    "3. If there is any mistake, correct it.\n",
    "4. If the code is missing some functionality, add it.\n",
    "5. pay extra attention to the data types and the every data processing steps like filtering, aggregation, and sorting.\n",
    "6. Return only the PySpark code.\"\"\",temperature=0.4,max_tokens=1000)\n",
    "\n",
    "print(((final_code.usage.prompt_tokens/1000) * 0.006)+((final_code.usage.completion_tokens/1000) * 0.012))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_code.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
